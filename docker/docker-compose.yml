services:
  minio:
    image: quay.io/minio/minio:RELEASE.2024-07-26T20-48-21Z
    command: server /data --console-address ":9090"
    ports:
      - "9000:9000"   # S3 API
      - "9090:9090"   # MinIO Console
    env_file:
      - ../.env
    volumes:
      - minio-data:/data

  postgres:
    image: postgres:14
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - pg-data:/var/lib/postgresql/data

  airflow:
    image: apache/airflow:2.9.3
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: dev
      AIRFLOW__CORE__FERNET_KEY: "youshouldsetthis"
    command: >
      bash -c "
      airflow db upgrade &&
      airflow users create --username admin --password admin --firstname a --lastname a --role Admin --email a@a.a || true &&
      airflow webserver & airflow scheduler
      "
    ports:
      - "8080:8080"
    volumes:
      - ../dags:/opt/airflow/dags
      - ../pipelines:/opt/airflow/pipelines
    env_file:
      - ../.env

  spark:
    build:
      context: ..
      dockerfile: docker/Dockerfile.spark
    depends_on:
      - minio
    env_file:
      - ../.env
    volumes:
      - ../pipelines:/workspace/pipelines
    command: bash -c "tail -f /dev/null"
    ports:
      - "4040:4040"   # Spark UI
    tty: true

volumes:
  minio-data:
  pg-data:
